---
title: "R Notebook"
output:
  pdf_document: default
  html_notebook: default
---

```{r}
library(keras)
library(formattable)
library(tidyverse)
library(caret)
```
#Partie 3: Classification d'images

Il s’agit d’images naturelles (au format JPEG) représentant des voitures, des chats et des fleurs. La tâche consiste à prédire le contenu de nouvelles images appartenant à l’un de ces trois types.

## Réseaux de Neurones -- CNN

```{r include=FALSE}
object_list <- c("car", "cat", "flower")
```

### Chargement des images
On normalise la taille de chaque image à 70x70. A cause de la limite de la taille du modèle(100 Mo), on minimise la taille d'image. La dimension 50x50 ne sera pas suffit de distinguer l'objet à l'oeil nu, on a donc fixer la taille vers 70x70.

```{r}
img_width <- 70
img_height <- 70
target_size <- c(img_width, img_height)

```
On définit le batch_size et l'epoch.
```{r}

batch_size <- 32
epochs <- 100

channels <- 3

```

### Exploration des données
Pour chaque classe d'image, on divise l'ensemble d'images vers train/validation/test, selon le proportion 70:15:15.
```{r include=FALSE}
# path to image folders
train_image_files_path <- "C:/Users/xingjian/Desktop/sy19_projet/images/images_train"
valid_image_files_path <- "C:/Users/xingjian/Desktop/sy19_projet/images/images_validation"
test_image_files_path <- "C:/Users/xingjian/Desktop/sy19_projet/images/images_test"

train_data_gen = image_data_generator(
  rescale = 1/255 #,
  #rotation_range = 40,
  #width_shift_range = 0.2,
  #height_shift_range = 0.2,
  #shear_range = 0.2,
  #zoom_range = 0.2,
  #horizontal_flip = TRUE,
  #fill_mode = "nearest"
)

valid_data_gen <- image_data_generator(
  rescale = 1/255
)  


test_data_gen <- image_data_generator(
  rescale = 1/255
)

# training images
train_image_array_gen <- flow_images_from_directory(train_image_files_path, 
                                                    train_data_gen,
                                                    target_size = target_size,
                                                    class_mode = "categorical",
                                                    classes = object_list,
                                                    seed = 42)

# validation images
valid_image_array_gen <- flow_images_from_directory(valid_image_files_path, 
                                                    valid_data_gen,
                                                    target_size = target_size,
                                                    class_mode = "categorical",
                                                    classes = object_list,
                                                    seed = 42)

test_image_array_gen <- flow_images_from_directory(test_image_files_path, 
                                                   test_data_gen,
                                                   target_size = target_size,
                                                   class_mode = NULL,
                                                   color_mode = "rgb",
                                                   batch_size = batch_size,
                                                   seed = 42,
                                                   shuffle = FALSE)
```
On calcule le nombre d'image pour chaque classe:
```{r}
table(factor(train_image_array_gen$classes))
table(factor(valid_image_array_gen$classes))
table(factor(test_image_array_gen$classes))
```
On a respectivement 590, 486, 521 images dans la classe cat, car et flower, soit 36.9%, 30.4% et 32.6%. C'est plutôt une distribution balance. 

On mets à l'échelle les valeurs de R/G/B pour chaque image vers 1/255, tel que les valeurs R/G/B reste dans l'intervalle [0,1].
```{r include=FALSE}
# number of training samples
train_samples <- train_image_array_gen$n

# number of validation samples
valid_samples <- valid_image_array_gen$n


test_samples <- test_image_array_gen$n

```


### Modèle CNN

L'étapes sont:

  1) Construire le modèle
  2) Compiler le modèle 
  3) Train/Fit les données au modèle
  4) Evaluer le modèle dans le test set
  5) Analyser le modèle et améliorer
  
Le modèle sera principalement composé par différents layers:
  1) Conv2D: 48 filters de taille (70x70)/(68x68)/(34x34)/(32x32)
    Ici on extrait des features depuis l'image.
  
  2) MaxPooling2D: Les images sont à moitié dimensionnées.
  
  3) Flatten: transforme le format des images d'une matrice 2d(16,16,48) en une matrice 1d de 16x16x48 éléments.
  
  4) ReLU: donner x, retourne max(x,0)
  
  5) Softmax: 3 neurones, probabilité que l'image appartient à l'une des classes.

```{r}
model<-keras_model_sequential()

model %>%
  layer_conv_2d(filter=48,kernel_size=c(3,3),padding="same",
                input_shape=c(70,70,3)) %>%
  layer_activation("relu") %>%
  layer_conv_2d(filter=48,kernel_size=c(3,3)) %>%
  layer_activation("relu") %>%
  layer_max_pooling_2d(pool_size=c(2,2)) %>%
  layer_dropout(0.25) %>%
  
  layer_conv_2d(filter=48 , kernel_size=c(3,3),padding="same") %>%
  layer_activation("relu") %>%
  layer_conv_2d(filter=48,kernel_size=c(3,3) ) %>%
  layer_activation("relu") %>%
  layer_max_pooling_2d(pool_size=c(2,2)) %>%
  layer_dropout(0.25) %>%
  
  layer_flatten() %>%
  layer_dense(512) %>%
  layer_activation("relu") %>%
  layer_dropout(0.5) %>%
  
  layer_dense(3) %>%
  
  layer_activation("softmax")

```
  
On compile le modèle.
```{r}
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(lr = 0.0001, decay = 1e-6),
  metrics = "accuracy"
)
summary(model)
```

On fit le modèle aux données de train set. 
```{r echo=FALSE}
hist <- model %>% fit_generator(
  # training data
  train_image_array_gen,
  
  # epochs
  steps_per_epoch = as.integer(train_samples / train_image_array_gen$batch_size), 
  epochs = epochs, 
  
  # validation data
  validation_data = valid_image_array_gen,
  validation_steps = as.integer(valid_samples / valid_image_array_gen$batch_size),
  
  # print progress
  verbose = 2,
  callbacks = list(
    # save best model after every epoch
    callback_model_checkpoint("C:/Users/xingjian/Desktop/sy19_projet/fruits_checkpoints.h5", save_best_only = TRUE),
    # only needed for visualising with TensorBoard
    callback_tensorboard(log_dir = "C:/Users/xingjian/Desktop/sy19_projet/logs")
  )
)

plot(hist)
```

Maintenant on fait les predictions sur le jeu de test:
```{r}
predictions1 <- model %>% predict_generator(test_image_array_gen, steps=test_image_array_gen$n/batch_size+1, verbose=1)

colnames(predictions1) <- c("car","cat","flower")

pred_labels<-colnames(predictions1)[apply(predictions1,1,which.max)]
proba<-apply(predictions1, 1, max)
stat_df <- as.data.frame(cbind(test_image_array_gen$filenames, round(proba*100,2), pred_labels))
colnames(stat_df) <- c("filename","proba","class")

fname<-as.factor(stat_df$filename)
y_label = c()
for(i in 1:length(fname)){
  if(grepl("cat", fname[i])==TRUE){
    y_label[i] <- "cat"
  }else if (grepl("flower", fname[i])==TRUE){
    y_label[i] <- "flower"
  }else{
    y_label[i] <- "car"
  }
}

y_label <- as.factor(y_label)

y_pred <- as.factor(stat_df$class)

cm <- confusionMatrix(data = y_pred, reference = y_label)
cm
```

On a 97.14% accuracy sur le jeu de test. 

Mais il existe encore le probabilité d'améliorer notre modèle. 


Tout d'abord, nous observons l'évolution du courbe loss du jeu de validation. Au début, la perte diminue continuellement de 0,5 à près de 0,2, mais elle commence à osciller autour de epoch=30, avec le nombre d'epoch augmente, le loss augmente.On peut dire que le modèle est instable. Observez ensuite la précision de l'ensemble d'apprentissage et de l'ensemble de validation et constatez que l'accuracy de l'ensemble d'apprentissage est proche de 1 et que l'aracy de l'ensemble de validation est stable à environ 95%, ce qui indique que le modèle est légèrement overfit.

Une solution est d'appliquer le méthode de data augmentation.

L'utilisation de la data augmentation consiste principalement à ajouter de petites noises ou des modifications aux images de training. D'une part, on pourra augmenter le nombre de images dans training pour améliorer la capacité de généralisation du modèle et, d'autre part, des données de bruit peuvent être ajoutées pour améliorer la robustesse du modèle. 

Les principales méthodes d'amélioration des données sont les suivantes: flip transform, crop random, color jittering, shift, scale, contrast, noise, rotation Transformation / réflexion , etc. 

Les opérations d'amélioration des données que je fais principalement sont les suivantes:

Découpe d'image: Générez un cadre rectangulaire plus petit que la taille de l'image, coupez l'image au hasard et utilisez enfin l'image dans le cadre rectangulaire comme données d'apprentissage.

Retourner l'image: Retournez l'image vers la gauche ou la droite.

Blanchiment de l'image: blanchir l'image, c'est-à-dire normaliser l'image elle-même en une distribution gaussienne (0,1).